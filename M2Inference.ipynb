{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/fs-v2.cs.lan/export/grad/msaad/polp_examples/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(4224)\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import json, os, pickle, random\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from model2.utils import sample_n_items_from_pickle, read_json_as_dict, train_epoch, test_epoch\n",
    "from model2.model import LSTMNextWordPredictor\n",
    "from model2.dataset import WordDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./data\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SAMPLE = int(300e3)\n",
    "VOCAB_SIZE = int(5e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sample_n_items_from_pickle(os.path.join(data_root, \"test_2.pkl\"), TEST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres2idx = read_json_as_dict(\"./data/genres2idx.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_values = list(genres2idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = WordDataset(test, VOCAB_SIZE, len(genres2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "dropout = 0.3\n",
    "genre_size = len(genres2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = read_json_as_dict('./data/vocab_2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt = torch.load('./model2_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMNextWordPredictor(\n",
       "  (seq_embedding): Embedding(5001, 64)\n",
       "  (genre_embedding): Linear(in_features=618, out_features=128, bias=True)\n",
       "  (lstm): LSTM(64, 128, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  (fc): Linear(in_features=256, out_features=5001, bias=True)\n",
       "  (dropout_layer): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMNextWordPredictor(\n",
    "    vocab_size=VOCAB_SIZE+1, \n",
    "    embedding_dim=embedding_dim, \n",
    "    hidden_dim=hidden_dim, \n",
    "    grene_size=genre_size, \n",
    "    num_layers=num_layers, \n",
    "    dropout=dropout)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, input_sequence, genre, vocab_inverse):\n",
    "    \"\"\"\n",
    "    Predict the next word given an input sequence of one-hot encoded words.\n",
    "    \n",
    "    :param model: Trained LSTM model\n",
    "    :param input_sequence: List of one-hot encoded words\n",
    "    :param vocab: Dictionary mapping words to indices\n",
    "    :param vocab_inverse: Dictionary mapping indices to words\n",
    "    :return: The predicted word\n",
    "    \"\"\"\n",
    "    # Ensure model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Convert input sequence to tensor\n",
    "    input_tensor = input_sequence.unsqueeze(0)  # Add batch dimension\n",
    "    genre = genre.unsqueeze(0)\n",
    "    if torch.cuda.is_available():\n",
    "        input_tensor = input_tensor.cuda()\n",
    "        genre = genre.cuda()\n",
    "\n",
    "    # Get predictions from the model\n",
    "    with torch.no_grad():\n",
    "        last_output = model(input_tensor, genre)\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probabilities = torch.nn.functional.softmax(last_output, dim=1)\n",
    "    # Pick the most likely word index\n",
    "    #_, max_idx = torch.max(probabilities, dim=1)\n",
    "    num_samples = 1\n",
    "    sample = torch.multinomial(probabilities, num_samples, replacement=True).item()\n",
    "    # Convert index to word\n",
    "    if sample == 5000:\n",
    "        return 'UNK'\n",
    "    predicted_word = vocab_inverse[str(sample)]\n",
    "\n",
    "    return predicted_word, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genreate_text(model, input_seq, genre, vocab_values, vocab_size = VOCAB_SIZE , n = 10):\n",
    "    \"\"\"\n",
    "    Generates text composed of n words\n",
    "    \n",
    "    :param model: Trained LSTM model\n",
    "    :param input_sequence: List of one-hot encoded words\n",
    "    :param vocab: Dictionary mapping indices to words\n",
    "    :param n: number of tokens to generate\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    predicted_words = []\n",
    "    _genre = torch.argmax(genre).item()\n",
    "    _genre = genres_values[int(_genre)]\n",
    "    print(f\"Genre: {_genre}\")    \n",
    "    initial_text = ' '.join([vocab[str(wrd.item())] if str(wrd.item()) in vocab else 'UNK' for wrd in input_seq])\n",
    "    for _ in range(n):\n",
    "        predicted_wrd =  predict_next_word(model, input_seq, genre, vocab)\n",
    "        if len(predicted_wrd) == 2:\n",
    "            predicted_wrd, idx = predicted_wrd\n",
    "        else:\n",
    "            idx = 5000\n",
    "            \n",
    "        predicted_words.append(predicted_wrd)\n",
    "        #new_word = torch.zeros((1, vocab_size))\n",
    "        input_seq = torch.cat((input_seq, torch.tensor([idx])), dim=0)\n",
    "        input_seq = input_seq[1:]\n",
    "        \n",
    "    predicted_text = ' '.join(wrd for wrd in predicted_words)\n",
    "    print(f\"Initial text: {initial_text}\")\n",
    "    print(f\"Generated text: {initial_text} {predicted_text}\")\n",
    "    \n",
    "    return initial_text, f\"{initial_text} {predicted_text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = 9545\n",
    "upper_bound = 9800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [random.randint(lower_bound, upper_bound) for _ in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre: Geography\n",
      "Initial text: UNK i was a playboy bunny to the moving tribute to her mother UNK song because she could not sing\n",
      "Generated text: UNK i was a playboy bunny to the moving tribute to her mother UNK song because she could not sing he do can UNK the only discovers and rest details that UNK UNK and UNK UNK to the UNK UNK\n",
      "Genre: Comix\n",
      "Initial text: living comes independence and UNK and in time elizabeth ann finds herself making friends and UNK her new family when\n",
      "Generated text: living comes independence and UNK and in time elizabeth ann finds herself making friends and UNK her new family when a UNK nations who have practical years fate upon an UNK center of justice young many UNK were UNK UNK\n",
      "Genre: Journal\n",
      "Initial text: deal with you may feel UNK in your UNK with family friends and even with god maybe you are UNK\n",
      "Generated text: deal with you may feel UNK in your UNK with family friends and even with god maybe you are UNK the children ago to marry the UNK boys they carries has UNK your courtroom UNK too is the stranger is\n",
      "Genre: Demons\n",
      "Initial text: parable holds hidden insights that point the way to happiness and UNK to the way open the cover and enter\n",
      "Generated text: parable holds hidden insights that point the way to happiness and UNK to the way open the cover and enter of love UNK would be high UNK by a sun wife UNK exciting years loose style the only novel whose\n",
      "Genre: Fiction\n",
      "Initial text: day and be UNK UNK others will find a good UNK of UNK UNK UNK UNK if you loved who\n",
      "Generated text: day and be UNK UNK others will find a good UNK of UNK UNK UNK UNK if you loved who UNK UNK his new book — they has it not why not how they UNK she can really much not\n",
      "Genre: Sexuality\n",
      "Initial text: UNK a UNK and combat UNK is more her style and red ’ s new UNK threatens to be short\n",
      "Generated text: UNK a UNK and combat UNK is more her style and red ’ s new UNK threatens to be short through reminder and uncle america breaking the library of the life for the UNK book on a theme UNK of\n",
      "Genre: Journal\n",
      "Initial text: is constantly UNK but is current at the time of publication they are in order starting with the most popular\n",
      "Generated text: is constantly UNK but is current at the time of publication they are in order starting with the most popular will plan join so yourself if gabriel as with our ages UNK how to UNK it to UNK of eye\n",
      "Genre: \n",
      "Initial text: a UNK older than her UNK years when her best friend UNK her into UNK the local UNK to UNK\n",
      "Generated text: a UNK older than her UNK years when her best friend UNK her into UNK the local UNK to UNK by her UNK or he has gone their next UNK to yet will do his children despite and UNK with\n",
      "Genre: Amish\n",
      "Initial text: will be UNK by the shadow for the first time a UNK of fear is UNK in UNK ’ s\n",
      "Generated text: will be UNK by the shadow for the first time a UNK of fear is UNK in UNK ’ s question and life when he UNK UNK to UNK even a week thing as has UNK days the healthy chapters\n",
      "Genre: Amish\n",
      "Initial text: story of creation as told by god UNK by the constant UNK and UNK of aunt UNK and uncle UNK\n",
      "Generated text: story of creation as told by god UNK by the constant UNK and UNK of aunt UNK and uncle UNK and it UNK a UNK UNK UNK for emotional as that soon UNK to UNK until the events and on\n",
      "Genre: Geology\n",
      "Initial text: UNK her UNK reputation as a UNK UNK are about as hard to UNK as black magic and as UNK\n",
      "Generated text: UNK her UNK reputation as a UNK UNK are about as hard to UNK as black magic and as UNK UNK her moment but a talented UNK with the UNK of the UNK UNK UNK UNK and UNK UNK in\n",
      "Genre: Dragons\n",
      "Initial text: members of his family die of UNK child abuse UNK and violence like many others he UNK all the problems\n",
      "Generated text: members of his family die of UNK child abuse UNK and violence like many others he UNK all the problems of its UNK UNK from the eternal UNK that so forget many now as never as the half as the\n",
      "Genre: Books About Books\n",
      "Initial text: the book as a guide to help his children live their lives in a way that would allow them to\n",
      "Generated text: the book as a guide to help his children live their lives in a way that would allow them to still some of success the classical and abuse enough by UNK rest and later UNK alive toward at UNK me\n",
      "Genre: Science\n",
      "Initial text: UNK UNK ce UNK UNK UNK UNK UNK UNK UNK UNK UNK de le UNK UNK UNK UNK UNK le\n",
      "Generated text: UNK UNK ce UNK UNK UNK UNK UNK UNK UNK UNK UNK de le UNK UNK UNK UNK UNK le UNK UNK UNK de transformed time profound UNK UNK UNK e UNK UNK UNK UNK UNK UNK UNK UNK UNK\n",
      "Genre: Science\n",
      "Initial text: almost UNK hundred years are they running a UNK UNK or a sophisticated con job scott needs to save soul\n",
      "Generated text: almost UNK hundred years are they running a UNK UNK or a sophisticated con job scott needs to save soul hard winter real adventure to a UNK missing of becoming his father to turn UNK UNK has sisters daily better\n",
      "Genre: Classic Literature\n",
      "Initial text: UNK UNK and UNK out UNK that too often passes for eternal truth think of it as a history of\n",
      "Generated text: UNK UNK and UNK out UNK that too often passes for eternal truth think of it as a history of UNK UNK note playing must another UNK and the fascinating UNK great married UNK — UNK UNK UNK UNK UNK\n",
      "Genre: \n",
      "Initial text: better while UNK UNK with dan for a UNK has seen every kind of UNK — beach UNK UNK UNK\n",
      "Generated text: better while UNK UNK with dan for a UNK has seen every kind of UNK — beach UNK UNK UNK UNK away into this story of UNK in the UNK UNK UNK ’ s great way they mean edmund become\n",
      "Genre: Brazil\n",
      "Initial text: UNK of a brutal UNK he is UNK by his mother as a UNK child the boy is UNK prince\n",
      "Generated text: UNK of a brutal UNK he is UNK by his mother as a UNK child the boy is UNK prince UNK is suspense as UNK when gives UNK a play are daughter in a madman he and UNK in UNK\n",
      "Genre: Teen\n",
      "Initial text: UNK magic UNK must choose between two men the real thing or the dream come to terms with her own\n",
      "Generated text: UNK magic UNK must choose between two men the real thing or the dream come to terms with her own work dark UNK and UNK and one UNK to the UNK UNK beyond just there extraordinary among a river or\n",
      "Genre: Internet\n",
      "Initial text: half a million copies since its original publication in UNK — is UNK UNK most diverse and timeless collection of\n",
      "Generated text: half a million copies since its original publication in UNK — is UNK UNK most diverse and timeless collection of america has get a collection in each two the world with fifteen save create ” a original list tragedy of\n"
     ]
    }
   ],
   "source": [
    "for idx in indices:\n",
    "    seq = test_dataset.__getitem__(idx)[0]\n",
    "    genre = test_dataset.__getitem__(idx)[1]\n",
    "    init, pred = genreate_text(model, seq, genre, vocab, n = 20)\n",
    "    lst.append((init, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polp_test",
   "language": "python",
   "name": "polp_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
